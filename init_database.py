# -*- coding: utf-8 -*-
import pandas as pd
from sqlalchemy import create_engine, text
from pathlib import Path
import os
from dotenv import load_dotenv

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å .env
load_dotenv()

# ‡∏™‡∏£‡πâ‡∏≤‡∏á connection string ‡∏à‡∏≤‡∏Å environment variables
DB_USER = os.getenv("DB_USER", "root")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_HOST = os.getenv("DB_HOST", "localhost")
DB_NAME = os.getenv("DB_NAME", "game_sales")

if not DB_PASSWORD:
    raise ValueError("‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ DB_PASSWORD ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .env")

engine = create_engine(f"mysql+mysqlconnector://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_NAME}")


def insert_unique(table, values):
    """Insert unique items safely using INSERT IGNORE."""
    with engine.begin() as conn:
        for v in values:
            conn.execute(
                text(f"INSERT IGNORE INTO {table} (name) VALUES (:val)"),
                {"val": v}
            )


def main():
    try:
        print("üì• ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î CSV...")
        
        # ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÅ‡∏ö‡∏ö‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ó‡∏ò‡πå (relative path)
        csv_path = Path(__file__).parent / "data" / "vgsales.csv"
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
        if not csv_path.exists():
            raise FileNotFoundError(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå CSV ‡∏ó‡∏µ‡πà: {csv_path}")
        
        df = pd.read_csv(csv_path)
        print(f"‚úî ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(df):,} ‡πÅ‡∏ñ‡∏ß")

        print("\nüßπ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
        df = df.dropna(subset=["Name", "Platform", "Genre", "Publisher"])
        df["Year"] = df["Year"].fillna(0).astype(int)
        print(f"‚úî ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î: {len(df):,} ‡πÅ‡∏ñ‡∏ß")

        # =====================================================
        # INSERT UNIQUE DIMENSION VALUES (SAFE)
        # =====================================================
        print("\nüì¶ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Platform/Genre/Publisher...")

        insert_unique("platform", df["Platform"].unique())
        print(f"  ‚úî Platform: {df['Platform'].nunique()} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        
        insert_unique("genre", df["Genre"].unique())
        print(f"  ‚úî Genre: {df['Genre'].nunique()} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        
        insert_unique("publisher", df["Publisher"].unique())
        print(f"  ‚úî Publisher: {df['Publisher'].nunique()} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")

        # =====================================================
        # LOAD ID MAPPING
        # =====================================================
        print("\nüîó ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î ID mapping...")

        plat_map = pd.read_sql("SELECT id, name FROM platform", engine).set_index("name")["id"]
        genre_map = pd.read_sql("SELECT id, name FROM genre", engine).set_index("name")["id"]
        pub_map = pd.read_sql("SELECT id, name FROM publisher", engine).set_index("name")["id"]

        # Map to FK
        df["platform_id"] = df["Platform"].map(plat_map)
        df["genre_id"] = df["Genre"].map(genre_map)
        df["publisher_id"] = df["Publisher"].map(pub_map)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ NULL ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        null_count = df[["platform_id", "genre_id", "publisher_id"]].isnull().sum().sum()
        if null_count > 0:
            print(f"‚ö†Ô∏è ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà map ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {null_count} ‡πÅ‡∏ñ‡∏ß")
            df = df.dropna(subset=["platform_id", "genre_id", "publisher_id"])
            print(f"‚úî ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏´‡∏•‡∏∑‡∏≠: {len(df):,} ‡πÅ‡∏ñ‡∏ß")

        # =====================================================
        # INSERT INTO VGSALES (FACT TABLE)
        # =====================================================
        print("\nüóÉ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á vgsales...")

        inserted_count = 0
        with engine.begin() as conn:
            for idx, row in df.iterrows():
                try:
                    conn.execute(text("""
                        INSERT IGNORE INTO vgsales
                        (`Rank`, game_name, Year,
                         NA_Sales, EU_Sales, JP_Sales, Other_Sales, Global_Sales,
                         platform_id, genre_id, publisher_id)
                        VALUES
                        (:rank, :name, :year,
                         :na, :eu, :jp, :other, :global,
                         :platform, :genre, :publisher)
                    """), {
                        "rank": int(row["Rank"]),
                        "name": str(row["Name"]),
                        "year": int(row["Year"]),
                        "na": float(row["NA_Sales"]),
                        "eu": float(row["EU_Sales"]),
                        "jp": float(row["JP_Sales"]),
                        "other": float(row["Other_Sales"]),
                        "global": float(row["Global_Sales"]),
                        "platform": int(row["platform_id"]),
                        "genre": int(row["genre_id"]),
                        "publisher": int(row["publisher_id"]),
                    })
                    inserted_count += 1
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                    if (idx + 1) % 1000 == 0:
                        print(f"  ... ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß {idx + 1:,}/{len(df):,} ‡πÅ‡∏ñ‡∏ß")
                        
                except Exception as e:
                    print(f"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÅ‡∏ñ‡∏ß {idx}: {e}")
                    continue

        print(f"\n‚úî ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {inserted_count:,} ‡πÅ‡∏ñ‡∏ß")
        print("\nüéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•!")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        print("\nüìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:")
        with engine.connect() as conn:
            result = conn.execute(text("SELECT COUNT(*) as count FROM vgsales")).fetchone()
            print(f"  ‚Ä¢ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Å‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {result[0]:,} ‡πÄ‡∏Å‡∏°")
            
            result = conn.execute(text("SELECT COUNT(*) as count FROM platform")).fetchone()
            print(f"  ‚Ä¢ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Platform: {result[0]} ‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°")
            
            result = conn.execute(text("SELECT COUNT(*) as count FROM genre")).fetchone()
            print(f"  ‚Ä¢ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Genre: {result[0]} ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó")
            
            result = conn.execute(text("SELECT COUNT(*) as count FROM publisher")).fetchone()
            print(f"  ‚Ä¢ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Publisher: {result[0]} ‡∏ú‡∏π‡πâ‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà")

    except FileNotFoundError as e:
        print(f"\n‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        print("üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå vgsales.csv ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå 'data'")
    except ValueError as e:
        print(f"\n‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤: {e}")
    except Exception as e:
        print(f"\n‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î: {e}")
        raise


if __name__ == "__main__":
    main()